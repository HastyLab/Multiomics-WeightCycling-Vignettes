---
title: "Vignette #1 - Preprocessing"
author: "Matthew A. Cottam"
date: "8/8/2021"
output:
  html_document: 
    toc: yes
    number_sections: yes
    keep_md: true
  html_notebook: 
    theme: united
    toc_float: yes
    toc: yes
    fig_height: 6
    number_sections: yes
---
# In this vignette

In this preprocessing vignette, we start with data that has already been processed through 10X CellRanger V3. Instructions for CellRanger can be found here: 
https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger. 

Herein, we will seek to do the following:

* Perform SoupX to identify and remove likely ambient mRNA signal.
* Generate a Seurat object for each sequencing lane.
* Demultiplex hashtags
* Remove poor quality cells

As an important note, although we do frequently use for loops, this vignette has some sections with redundant code (repeated for each sample). Experienced users can write loops or use `lapply` to complete many of these preliminary tasks.

This vignette has been tested on both linux (Ubuntu 20.04.2) and macOS (Big Sur 11.5.1).

# Prepare the R environment

## Load in the necessary libraries

We use a variety of critical libraries to facilitate data processing and analysis. Most importantly, SoupX
```{r setup, message=FALSE, warning=FALSE}
library(SoupX)
library(Seurat)
library(ggplot2)
library(cowplot)
library(viridis)
```

# SoupX Counts Correction

SoupX calculates the background contamination from free-floating RNA (the soup) that is sequenced along with cell RNA in the droplet and corrects for this ambient RNA contamination.

SoupX provides a simple workflow and functions to read in 10X CellRanger outputs. Fraction of contaminating background RNAs are parametrised as `rho` where `rho=0` means no contamination and `rho=1` means 100% of UMIs in the droplet were from soup RNA.

More about SoupX:
Young, M.D., Behjati, S. (2020). SoupX removes ambient RNA contamination from droplet-based single-cell RNA sequencing data, GigaScience, Volume 9, Issue 12, December 2020, giaa151bioRxiv, 303727, https://doi.org/10.1093/gigascience/giaa151

## Load in the datafiles

SoupX needs the filtered and raw barcode matrices found in the output folder from 10X CellRanger. In this experiment, these files are larger and therefore we've used gitLFS to store them for this vignette. You can learn more about gitLFS here: https://git-lfs.github.com/.

In addition to the barcode matrices, SoupX strongly recommends some clustering information, which can be found in the 10X CellRanger output folder "analysis". 

```{r datafiles}
# Read datafiles into SoupX
Lean_soup <- load10X("../10xCellRanger/Lean/")
Obese_soup <- load10X("../10xCellRanger/Obese/")
WL_soup <- load10X("../10xCellRanger/WL/")
WC_soup <- load10X("../10xCellRanger/WC/")
```

## Estimate cell specific contamination fraction

```{r soup, fig.width=5, fig.height=5}
soup_list <- list(Lean_soup = Lean_soup, 
                  Obese_soup = Obese_soup, 
                  WL_soup = WL_soup, 
                  WC_soup = WC_soup)
for (i in seq_along(soup_list)){
  soup_list[[i]] <- autoEstCont(soup_list[[i]])
}
```

## Infer corrected expression matrix

```{r soupcorrect, warning=FALSE}
sample_list <- list()
for (i in seq_along(soup_list)){
  sample_list[[i]] <- adjustCounts(soup_list[[i]]) #Note, these outputs are stored as a separate sparse matrix.
}
```

The correction for specific genes can be visualized. For example, Igkc, an immunoglobulin coding gene, should be limited to mostly B cells. However, contaminated Igkc in the soup makes other cell types express Igck. SoupX adjusts for this.
Below, I've plotted Igkc contamination overlapped onto the tSNE projections calculated by CellRanger for the weight cycled sample.

```{r soupplot, fig.width=10, fig.height=4.5, message=FALSE}
tSNE_data <- soup_list[["WC_soup"]]$metaData
tSNE_data$clusters <- factor(tSNE_data$clusters)
soup1 <- ggplot(tSNE_data, aes(tSNE1, tSNE2, color=clusters)) + geom_point(size = 0.2) + theme_bw()
soup2 <- plotChangeMap(soup_list[["WC_soup"]], sample_list[[4]], "Igkc") + theme_bw() + scale_color_viridis(option="viridis")
soup1 + soup2
```

# Create the Seurat object

## Read in datafiles from 10X CellRanger outputs

This is a multimodal study. We will use the corrected counts from SoupX and the ADT/HTO data that remains in the original CellRanger outputs.

```{r cellranger}
# Read in datafiles from CellRanger
Lean.data <- Read10X("../10xCellRanger/Lean/filtered_feature_bc_matrix/")
Obese.data <- Read10X("../10xCellRanger/Obese/filtered_feature_bc_matrix/")
WL.data <- Read10X("../10xCellRanger/WL/filtered_feature_bc_matrix/")
WC.data <- Read10X("../10xCellRanger/WC/filtered_feature_bc_matrix/")
```

## Using SoupX objects to create the Seurat object

```{r seuratobj}
# Create a Seurat object list using the SoupX adjusted matrices
# The project name is stored in the `orig.ident` metadata column, which we use frequently later.
Seurat_list <- list(Lean = CreateSeuratObject(sample_list[[1]], project = "Lean"), Obese = CreateSeuratObject(sample_list[[2]], project = "Obese"), WL = CreateSeuratObject(sample_list[[3]], project = "WL"), WC = CreateSeuratObject(sample_list[[4]], project = "WC"))

# Take a look at the structure of this new list:
Seurat_list
```

## Rename the CITE-seq antibodies.

CITE-seq antibodies had long names from our original 10X CellRanger run, which also indicate which TotalSeq-C antibody they originally were. We can adjust these names for downstream processing so that they are easier to read. These names are found in the `Antibody Capture` assay.

```{r NameAbs}
#Explore which antibodies were included in the experiment.
rownames(Lean.data[["Antibody Capture"]])
```

```{r RenameAbs}
#Create a list with new antibody names
Antibody.list <- c("Hashtag1", "Hashtag2", "Hashtag3", "Hashtag4", 
                   "Hashtag5", "Hashtag6", "Hashtag8", "Hashtag9", 
                   "MAC2", "CD279", "CD64", "CD4", 
                   "CCR7", "CD80", "CD11c", "CD44", 
                   "NK1.1", "TCRyd", "CD39", "CD19", 
                   "CD11b", "CD3", "TIGIT", "CD8a")
```

Adjust antibody names for clarity and create separate matrices for Hashtag and CITE-seq antibodies

```{r appAbs}
#Apply the renamed antibody list
rownames(x = Lean.data[["Antibody Capture"]]) <- Antibody.list
rownames(x = Obese.data[["Antibody Capture"]]) <- Antibody.list
rownames(x = WL.data[["Antibody Capture"]]) <- Antibody.list
rownames(x = WC.data[["Antibody Capture"]]) <- Antibody.list
```

```{r MatrixAbs}
#Create a matrix containing the ADT and HTO names. We only need to do this for one sample since they are the same for all lanes in this experiment
HTOs <- Lean.data$'Antibody Capture'@Dimnames[[1]][1:8]
HTO <- Lean.data$'Antibody Capture'[HTOs, ]
ADTs <- Lean.data$'Antibody Capture'@Dimnames[[1]][9:24]
ADT <- Lean.data$'Antibody Capture'[ADTs, ]
```

```{r AbCounts}
#Antibody Capture Assay (Feature Barcoding; Hashtags)
Lean.ADT.counts <- Lean.data$'Antibody Capture'[ADTs, ]
Obese.ADT.counts <- Obese.data$'Antibody Capture'[ADTs, ]
WL.ADT.counts <- WL.data$'Antibody Capture'[ADTs, ]
WC.ADT.counts <- WC.data$'Antibody Capture'[ADTs, ]

Lean.HTO.counts <- Lean.data$'Antibody Capture'[HTOs, ]
Obese.HTO.counts <- Obese.data$'Antibody Capture'[HTOs, ]
WL.HTO.counts <- WL.data$'Antibody Capture'[HTOs, ]
WC.HTO.counts <- WC.data$'Antibody Capture'[HTOs, ]
```

In this experiment, Hashtags 5-6 and 8-9 were used in the Lean and WL lanes, while 1-4 were used in the Obese and WC lanes.

```{r rAbs}
#Remove HTOs that were not included in the lane
Lean.HTO.counts <- Lean.HTO.counts[setdiff(rownames(x = Lean.HTO.counts), c("Hashtag5", "Hashtag6", "Hashtag8", "Hashtag9")), ]
Obese.HTO.counts <- Obese.HTO.counts[setdiff(rownames(x = Obese.HTO.counts), c("Hashtag1", "Hashtag2", "Hashtag3", "Hashtag4")), ]
WL.HTO.counts <- WL.HTO.counts[setdiff(rownames(x = WL.HTO.counts), c("Hashtag5", "Hashtag6", "Hashtag8", "Hashtag9")), ]
WC.HTO.counts <- WC.HTO.counts[setdiff(rownames(x = WC.HTO.counts), c("Hashtag1", "Hashtag2", "Hashtag3", "Hashtag4")), ]
```

## Integrate the `Antibody Capture` assays into the SoupX-corrected Seurat object

We will store the CITE-seq antibodies in the `ADT` assay and the hashtags in the `HTO` assay.

```{r AbAssays}
#Create the Antibody Capture assay object "ADT" and the Hashtag assay object "HTO".
Seurat_list[["Lean"]][['ADT']] <- CreateAssayObject(counts = Lean.ADT.counts)
Seurat_list[["Obese"]][['ADT']] <- CreateAssayObject(counts = Obese.ADT.counts)
Seurat_list[["WL"]][['ADT']]  <- CreateAssayObject(counts = WL.ADT.counts)
Seurat_list[["WC"]][['ADT']] <- CreateAssayObject(counts = WC.ADT.counts)

Seurat_list[["Lean"]][['HTO']]  <- CreateAssayObject(counts = Lean.HTO.counts)
Seurat_list[["Obese"]][['HTO']]  <- CreateAssayObject(counts = Obese.HTO.counts)
Seurat_list[["WL"]][['HTO']]  <- CreateAssayObject(counts = WL.HTO.counts)
Seurat_list[["WC"]][['HTO']]  <- CreateAssayObject(counts = WC.HTO.counts)

# Take a look at the structure of this updated list:
Seurat_list
```

## Store original barcodes

The original cell identity is indicated by the cell barcode. As a precaution, I store the original cell barcodes as a metaData column. This protects these original names for later if we need to use them to match other tools after integrating our four lanes (which may have duplicate barcodes).

```{r barcodes}
#Store cell barcodes as a metadatacolumn in case we need them later:
for (i in seq_along(Seurat_list)){
  Seurat_list[[i]]$orig.barcodes <- rownames(Seurat_list[[i]][[]]) 
}
```

# Quality Control

Quality control of sample cells is a critical step in processing of scRNA-seq data. Our QC relies on four parameters for this dataset:
1. Less than 5% mitochondrial RNA content
2. Greater than 200 measured gene features
3. Greater than 500 total RNA fragments measured
4. Singlets as determined by hashtag demultiplexing

Mitochondrial RNA content can be used to predict which cells were likely undergoing mechanisms of cell death. The recommendation from the Satija lab (Seurat) and the Theis lab (SCANPY), among others, is to set the upper limit for mitochondrial RNA to 5% for murine cells (10% for human cells).

## Calculate the per-cell mitochondrial RNA content

```{r pctMt}
for (i in seq_along(Seurat_list)){
  Seurat_list[[i]]$percent.mt <- PercentageFeatureSet(Seurat_list[[i]], pattern = "^mt-") 
}
```

## Visualize QC features

It is helpful to visualize mitochondrial RNA content as a function of the number of UMIs measured per cell and of the number of features (genes) per cell. Here, we can observe that cells with more RNA fragments counted tend to have more features (genes) as expected. We can also observe that cells with few features (genes) and few counts frequently have higher mitochondrial content. 

To do this, we use one of the visualization functions built into Seurat V4: `FeatureScatter`.

```{r QCMetrics, fig.width=12, fig.height=4}
#Visualize QC Metrics using scatter plots
for (i in seq_along(Seurat_list)){
  qc1 <- FeatureScatter(Seurat_list[[i]], feature1 = "nFeature_RNA", feature2 = "nCount_RNA") 
  qc2 <- FeatureScatter(Seurat_list[[i]], feature1 = "nFeature_RNA", feature2 = "percent.mt")  
  qc3 <- FeatureScatter(Seurat_list[[i]], feature1 = "nCount_RNA", feature2 = "percent.mt")
  print(qc1 + qc2 + qc3)
} 
```

## Subset cells

The QC parameters will be used to subset the data so that we only retain cells which are considered to be of acceptable quality based on number of RNA features, total RNA fragments measured, and frequency of mitochondrial RNA.

```{r QCsubset}
for (i in seq_along(Seurat_list)){
  Seurat_list[[i]] <- subset(Seurat_list[[i]], subset = nFeature_RNA > 200 & nCount_RNA > 500 & percent.mt<5)
}

#Check the updated sample list to see how many cells were retained.
Seurat_list
```

# Demultiplexing Hashtags

In this study, hashtags were used to dilineate biological replicates. First, the hashtags will be normalized using Centered Log Ratio (CLR) normalization. After confirming proper enrichment for each hashtag, we will subset the data so that only cells which are described as singlets will be retained for downstream analysis.

## Normalize hashtag data

To use CLR normalization, simply pass the option `normalization.method = "CLR"`. Be sure to also indicate that the `HTO` assay should be normalized.

```{r HTONorm, message=FALSE}
for (i in seq_along(Seurat_list)){
  Seurat_list[[i]] <- NormalizeData(Seurat_list[[i]], assay="HTO", normalization.method="CLR", verbose=FALSE)
}
```

## Demultiplex

Use Seurat's `HTODemux` function to demultiplex the hashtags using the sample assay. This function also stores numerous metadata columns. The two used most frequency are: 

1. Global classification - Indicates whether cells are unlabeled, singlets, or doublets.
2. HTO max ID - Indicates the most likely ID based on hashtags.

We use the default 99% positive quantile, which should provide confidence that singlets are accurately identified.

```{r HTODemux}
for (i in seq_along(Seurat_list)){
  Seurat_list[[i]] <- HTODemux(object = Seurat_list[[i]], assay = "HTO", positive.quantile=0.99)
}
```

## Visualize hashtag demultiplexing

To visualize how well separated hashtags are, we use another one of Seurat V4s functions: `RidgePlot`.

```{r HTOenrichment, fig.width=8, fig.height=6}
for (i in seq_along(Seurat_list)){
  Idents(Seurat_list[[i]]) <- "HTO_maxID" #Change the ident so that we plot the most likely sample ID.
  print(RidgePlot(Seurat_list[[i]], assay = "HTO", features = rownames(Seurat_list[[i]][["HTO"]])[1:4], ncol = 2) & labs(y="", subtitle=names(Seurat_list[i])))
}
```

We can also calculate the frequency of singlets and report it in a table before subsetting. In this experiment, we observe that WL and WC samples had a higher frequency of "Negative" samples. These are cells in which surface Hashtag staining was too low for any specific antibody. This is likely due to insufficient antibody labeling. However, we retain enough cells even with a very strict cutoff for subsequent analysis.

```{r HTOProps}
for (i in seq_along(Seurat_list)){
  print(names(Seurat_list)[i])
  print(prop.table(table(Seurat_list[[i]]$HTO_classification.global)))
}
```

## Subset singlets

Finally, we will subset cells so that we only retain singlets for downstream processing

```{r subSinglets}
for (i in seq_along(Seurat_list)){
  Idents(Seurat_list[[i]]) <- "HTO_classification.global" #Change the ident
  Seurat_list[[i]] <- subset(Seurat_list[[i]], idents = "Singlet")
}

#Take a look at how many cells are retained after final QC.
Seurat_list
```

# Save Progress

The next vignette will show how we integrated our data and performed dimensional reduction. To save our current project, we will use the `saveRDS` function. This file is about 1.1gb and it seems unnecessary to move it around. Therefore, I've included all `.rds` files as part of the `git ignore` file. These will not be downloaded when the repository is cloned.

```{r save}
saveRDS(Seurat_list, file="1_Preprocessing.rds")
```

# Session Info

```{r session info}
sessionInfo()
```

